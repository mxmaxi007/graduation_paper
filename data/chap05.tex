\chapter{基于变长语音段的情感识别}
\label{cha:var_len}

\section{本章引论}
\label{sec:var_len_intro}

上一章我们介绍了基于深度神经网络的端到端的语音情感识别系统，但是为了方便神经网络模型处理，一个完整的语音句子被切分成了更小的等长语音段，每一个语音段都被标记为对应句子的情感类别。这样的处理方式会引入一些问题，因为在我们实际的观测中，一个非中性的句子中并不是所有的部分都会包含有明显的情感信息，往往只有一部分语音包含。当我们将句子切分成多个语音段时，可能并不是所有的语音段都包含有情感信息，当仍然会将不包含情感信息的语音段标记为句子的情感类别。这样的数据在训练模型时会对模型造成混淆，因为同样的中性语音段，有的被标记为中性，有的被标记为其他情感，使得模型无法区分哪些应该是真正的中性语音。除了对中性情感的识别会产生影响以外，由于在预测时是所有的语音段来决定句子最终的情感类别，而带情感的句子的中性语音段之间区别也不大，所以也有可能会导致识别时发生混淆。

为了进一步验证我们对于句子中只有部分的语音段包含有明显的情感信息这一猜测，下面图1展示了一个标记为愤怒的句子中前后两个语音段的语谱图，其中横轴代表时间，纵轴代表频率，颜色越深代表能量越高。通常来说，愤怒的语音在各个频段的能量都相对较高，可以看到图中右边的语音段的能量较高，看上去更像一段愤怒的语音，而左边的语音段则看上去不像愤怒语音。通过人工听测这两个语音段，同样也发现左边的语音段听上去包含有更多的愤怒情感，右边的语音段听上去更像中性语音。然而，当我们直接听整个句子时，却发现前面中性语音段可以增强后面的愤怒语音段的愤怒感觉，也就是所谓的欲扬先抑。因此，我们认为设计一种可以处理变长语音段的神经网络结构，从而将整个句子作为输入能够更好地提升模型的识别率。

\begin{figure}[H] % use float package if you want it here
    \centering
    \includegraphics[height=10cm]{myfigures/2dim_space}
    \caption{激活度-效价情感空间模型}
    \label{fig:xfig1}
\end{figure}

本章剩余的部分是这样安排的：首先我们将介绍如何实现能够处理变长输入的深度神经网络模型，然后将介绍变长语音段如何抽取语谱图，最后将通过实验比较定长输入的神经网络和变长输入的神经网络在识别效果上的差异。

\section{变长语音段的语谱图抽取}

本章采取的语谱图抽取参数和上一章相同，唯一不同的是我们将对整个句子进行语谱图抽取，而不是对切分的等长语音段。由于在进行神经网络训练时，通常会将多个样本组成一个批次(Batch)，然后一起放进模型调整参数。同时，一个批次中的数据长度需要相同，而语谱图的长度各不相同，所以需要通过将一个批次中的数据都用0补齐到最长语谱图的长度。为了提升计算效率，所有的语谱图将会按照时间长度进行排序，然后将时间长度接近的语谱图放入一个批次，这样可以保证需要补齐的0最少，从而可以节约存储空间，增加计算速度。

\section{变长神经网络结构}
\label{sec:var_len_nn}

在上一章基于深度神经网络的端到端的语音情感识别系统中，我们主要采用了两种神经网络结构：卷积神经网络(Convolution Neutral Network, CNN)和循环神经网络(Recurrent Neural Network, RNN)。这两种神经网络结构通常的用法都是处理定长的输入，但它们同样也具备处理变长输入的能力。为了方便描述，假设输入序列为$\mathbf{s} = \{x_1, x_2,...,x_V,...,x_T\}$，其中$\mathbf{s1} = \{x_1, x_2,...,x_V\}$是有效的部分，$\mathbf{s2} = \{x_{V+1}, x_{V+2},...,x_T\}$是补齐的0。我们设计神经网络的主要目的就是不让补齐的0对最终的结果产生影响，下面将介绍本文是如何实现变长的CNN和RNN的。

\subsection{变长卷积神经网络}
\label{ssec:var_len_cnn}

卷积神经网络(Convolution Neutral Network, CNN)是通常是处理定长的输入，特别是在计算机视觉领域，但CNN本身只是在训练卷积核，而这些卷积核和输入的大小是无关的，因此CNN具备处理变长输入的能力。为了只保留有效的输入$s1$对输出结果的影响，，我们将采用掩码(Masking)去屏蔽补齐的无效输入$s2$所产生的输出，如下面的公式所示：
\begin{equation}
\label{equ:cnn_mask}
    s_Conv = Conv(s) \bullet Mask(s)
\end{equation}
其中$Conv(s)$代表序列$s$在经过卷积层后的输出，$Mask(s)$代表掩码矩阵，矩阵中代表有效部分的位置被置为1，无效部分的位置被置为0，最终的有效输出为$s_Conv=\{y1,y2,...,y_V,....,y_T\}$，是$Conv(s)$和$Mask(s)$通过点乘运算(Element-Wise Multiply)得到的。此外，卷积层后面的通常都会连接一个池化层(Pooling Layer)，我们也需要关注有效部分和无效部分的边界，因为这里有可能会引入无效的信息。例如，假设$s_Conv$是最大值池化层(Max-Pooling Layer)的输入，如果池化层的单元大小为2，一个单元的输入为$y_V$和$y_{V+1}$，则当$y_V<0$且$Y_{V+1}=0$时，这个单元的输出为0，然而我们期望的输出应该是$y_V$，因为$Y_{V+1}$是无效部分得到的输出。在实际的测试中，我们发现这样无效信息的引入会导致神经网络无法收敛。因此，$y_V$所在位置的掩码也会被设置为0，这样输入最大值池化层时就不会引入无效的信息了。通过加入掩码矩阵的方法，我们可以保证补齐的0不会对CNN的输出产生影响，这可以保证相同输入在训练和测试阶段可以得到相同的输出，因为在测试阶段样本是不会用0补齐的。

\subsection{变长循环神经网络}
\label{ssec:var_len_rnn}

循环神经网络(Recurrent Neural Network, RNN)是用来建模语音信号的时序信息的，对于每一个时间步的输出都采用相同的参数进行计算，同样也可以用来处理变长的序列输入。由于语音情感识别输入序列分类任务，所以我们只需要RNN最后一个时间步的输出。假设$s$是RNN的输入，期望的结果是时间步$t=V$时的输出，所以我们可以忽略$t=V+1$以后的所有输出，保证无效的补齐部分不会对输出产生影响。此外，对于双向的RNN，反向的RNN将会输出$t=0$时的输出，所以最后输出会将正向和反向的结果拼接在一起。

\section{实验结果及分析}
\label{sec:var_len_experiment}

前面几节详细的介绍了如何设计深度神经网络来处理变长的语音段，下面我们将通过实验来对比采用上一章的定长方法和本章的变长方法之间的效果差别。

\subsection{实验设置}
\label{sec:var_len_experiement_setup}

数据库同样是采用IEMOCAP情感语音数据库，其他实验设置和上一章的相同，唯一不同的就是模型的语谱图输入在时域上不是固定大小了，而是和语音句子的长度相关。下面图2是通过实验得到的最佳神经网络结构，其中$T$时语音句子的时间长度，$N$是语谱图的时域长度。

\begin{figure}[H] % use float package if you want it here
    \centering
    \includegraphics[height=10cm]{myfigures/2dim_space}
    \caption{激活度-效价情感空间模型}
    \label{fig:xfig1}
\end{figure}

\subsection{实验结果}
\label{sec:var_len_experiement_result}

实验结果主要可以分为两个部分，第一部分主要比较了定长方法和本章的变长方法之间识别率的差异；第二部分主要通过图像来展示RNN不同节点在不同时间步的激活程度，从而进一步证明变长的方法可以减轻模型对于不同情感的混淆。

\subsubsection{准确率对比}
\label{sec:var_len_experiement_acc}
本次实验的评价指标仍然是加权准确率(Weighted Accuracy, WA)和不加权准确率(Unweighted Accuracy, UA)，在下面的表\ref{tab:acc_var_len}中，我们展示了上一章定长方法取得的最好的结果，由于本章采用的网络结构和上一章不同，所以也会展示定长的输入在本章神经网络模型上的结果，以及变长的输入在本章神经网络上的结果，其中，“最佳结果”代表上一章的最好的结果，“定长模型”和“变长模型”分别代表代表在本章设计的神经网络模型下定长输入和变长输入得到的结果。从实验结果中我们可以看出，当采用变长的神经网络结构时，相比于定长的方法，在WA和UA上均得到了提升。这证明采用变长的输入比切分成定长的输入能够取得更好的效果。
\begin{table}[htb]
\centering
\begin{minipage}[t]{0.8\linewidth} % 如果想在表格中使用脚注，minipage是个不错的办法
\caption{不同方法的准确率}
\label{tab:acc_var_len}
    % \begin{tabular}{p{6cm}<{\centering} p{6cm}<{\centering}}
    \begin{tabularx}{\linewidth}{X<{\centering} X<{\centering} X<{\centering}}
        \toprule[1.5pt]
        模型 & WA & UA \\
        \midrule[1pt]
        最佳结果 & 67.30\% & 62.00\% \\
        定长模型 & 68.86\% & 57.45\% \\
        变长模型 & \textbf{71.45\%} & \textbf{64.22\%} \\
        \bottomrule[1.5pt]
    \end{tabularx}
\end{minipage}
\end{table}

为了进一步分析实验结果，我们在下面的表格\ref{tab:cm_const_len}和表格\ref{tab:cm_var_len}中分别展示了定长输入和变长输入在本章的神经网络结构中得到的混淆矩阵。我们可以看到中性情感在变长方法的识别率提升了，正如我们在\ref{sec:var_len_intro}节分析的，当整个句子输入模型时可以减轻中性情感和其他情感的混淆。此外，高兴的准确率也得到了显著的提升，这或许是因为定长方法中，高兴句子切分出的语音段大多为中性情感，所以会被错分为其他情感。还有就是悲伤的识别率降低了，这或许是因为其他情感的准确率提升了，所以导致一些悲伤的语音被错分到其他情感。这些结果可以证明变长的方法确实能够提升部分情感的识别率。

\begin{table}[htb]
\centering
\begin{minipage}[t]{0.8\linewidth} % 如果想在表格中使用脚注，minipage是个不错的办法
\caption{混淆矩阵（定长输入）}
\label{tab:cm_const_len}
    % \begin{tabular}{p{6cm}<{\centering} p{6cm}<{\centering}}
    \begin{tabularx}{\linewidth}{X|X|X|X|X}
        \toprule[1.5pt]
        \diagbox[width=5em,trim=l]{实际}{预测} & 中性 & 愤怒 & 高兴 & 悲伤 \\
        \midrule[1pt]
        中性 & \textbf{71.75\%} & 8.88\% & 5.93\% & 13.45\% \\
        愤怒 & 30.84\% & \textbf{58.79\%} & 7.05\% & 3.34\% \\
        高兴 & 55.92\% & 31.42\% & \textbf{11.72\%} & 0.95\% \\
        悲伤 & 11.41\% & 0\% & 1.02\% & \textbf{87.57\%} \\
        \bottomrule[1.5pt]
    \end{tabularx}
\end{minipage}
\end{table}

\begin{table}[htb]
\centering
\begin{minipage}[t]{0.8\linewidth} % 如果想在表格中使用脚注，minipage是个不错的办法
\caption{混淆矩阵（变长输入）}
\label{tab:cm_var_len}
    % \begin{tabular}{p{6cm}<{\centering} p{6cm}<{\centering}}
    \begin{tabularx}{\linewidth}{X|X|X|X|X}
        \toprule[1.5pt]
        \diagbox[width=5em,trim=l]{实际}{预测} & 中性 & 愤怒 & 高兴 & 悲伤 \\
        \midrule[1pt]
        中性 & \textbf{73.64\%} & 2.74\% & 12.41\% & 11.21\% \\
        愤怒 & 11.44\% & \textbf{59.55\%} & 26.52\% & 2.5\% \\
        高兴 & 45.20\% & 13.81\% & \textbf{40.05\%} & 0.95\% \\
        悲伤 & 15.89\% & 0\% & 0.48\% & \textbf{83.64\%} \\
        \bottomrule[1.5pt]
    \end{tabularx}
\end{minipage}
\end{table}

\subsubsection{循环神经网络输出}
\label{sec:var_len_experiement_rnn}

通过观察神经网络的激活输出能够验证网络学习到的信息，下面的图2展示了一个中性语音的句子通过神经网络后RNN不同节点的激活输出。左边的图片代表定长神经网络，右边的图片代表变长神经网络，其中横轴代表时间，纵轴代表RNN不同的节点，颜色越深代表激活程度越高。从图中可以观察到右边图片中的条纹比左边图片中的要清晰很多。此外，我们也发现特定的情感在特定的节点上有更高的激活值。图3展示了三种不同情感的语音在变长网络中的RNN的不同节点的激活输出，红色方框中的是高激活度的节点。从图中可以发现高兴和愤怒的激活节点比较相似，因为这两种情感的声学表现也比较相似，而悲伤地激活节点和高兴的激活节点就有明显的不同。不过中性情感无法找到特定的激活节点，这可能是因为中性语音没有一种特别明显的声学表现。这些不同情感对应的激活节点可以在变长网络中清楚地观察到，但在定长网络中，由于条纹非常模糊，所以很难观察到这样的现象。这些实验结果进一步证明了变长的方法能够减轻模型对不同情感的混淆。

\begin{figure}[H] % use float package if you want it here
    \centering
    \includegraphics[height=10cm]{myfigures/2dim_space}
    \caption{激活度-效价情感空间模型}
    \label{fig:xfig1}
\end{figure}

\begin{figure}[H] % use float package if you want it here
    \centering
    \includegraphics[height=10cm]{myfigures/2dim_space}
    \caption{激活度-效价情感空间模型}
    \label{fig:xfig1}
\end{figure}

\section{本章小结}
\label{sec:var_len_summary}

本章主要设计了一种能够处理变长语音段输入的深度神经网络结构，相比于上一章提出的定长输入的深度神经网络模型，可以有效地减轻模型对不同情感的混淆。在情感语音数据库IEMOCAP上，变长的方法方法相比于定长的方法能够取得更好的识别率。